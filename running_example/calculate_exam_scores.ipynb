{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file():\n",
    "    while True:\n",
    "        try:\n",
    "            name_file = input(\"Enter a class file to grade (e.g., class1 for class1.txt): \")\n",
    "            with open(f\"./Data_Files/input/{name_file}.txt\", 'r') as file:\n",
    "                file_read = file.read().splitlines()\n",
    "            print(f\"Successfully opened {name_file}.txt\")\n",
    "            return file_read, name_file\n",
    "        except FileNotFoundError:\n",
    "            print(\"File cannot be found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully opened class8.txt\n"
     ]
    }
   ],
   "source": [
    "file_read, name_file = read_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzing_data(file_read):\n",
    "    print(\"****ANALYZING****\")\n",
    "    count = len(file_read)\n",
    "    error_count = 0\n",
    "    correct_exams = []\n",
    "\n",
    "    for line in file_read:\n",
    "        res = re.findall(r\"[N]\\d{8}\", line)\n",
    "        if not res:\n",
    "            error_count += 1\n",
    "            print(f\"Invalid line of data: N# is invalid \\n {line}\")\n",
    "        else:\n",
    "            element = line.split(\",\")\n",
    "            if len(element) != 26:\n",
    "                error_count += 1\n",
    "                print(f\"Invalid line of data: does not contain exactly 26 values:\\n {line}\")\n",
    "            else:\n",
    "                correct_exams.append(line)\n",
    "\n",
    "    if error_count == 0:\n",
    "        print(\"No error found!\")\n",
    "\n",
    "    print(\"****REPORT****\")\n",
    "    print(f\"Total valid lines of data:\", count - error_count)\n",
    "    print(f\"Total invalid lines of data:\", error_count)\n",
    "    \n",
    "    return correct_exams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****ANALYZING****\n",
      "No error found!\n",
      "****REPORT****\n",
      "Total valid lines of data: 49\n",
      "Total invalid lines of data: 0\n"
     ]
    }
   ],
   "source": [
    "correct_exams = analyzing_data(file_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_key = \"B,A,D,D,C,B,D,A,C,C,D,B,A,B,A,C,B,D,A,C,A,A,B,D,D\"\n",
    "def calculate_scores(correct_exams, answer_key):\n",
    "    lst_of_scores = []\n",
    "    skip_questions = {}\n",
    "    wrong_questions = {}\n",
    "\n",
    "    keys = answer_key.split(\",\")\n",
    "    for exam in correct_exams:\n",
    "        result = exam.split(\",\")\n",
    "        score = 0\n",
    "        for idx, answer in enumerate(result[1:], start=1):\n",
    "            if answer == '':\n",
    "                skip_questions[idx] = skip_questions.get(idx, 0) + 1\n",
    "            else:\n",
    "                if answer == keys[idx - 1]:\n",
    "                    score += 4\n",
    "                else:\n",
    "                    score -= 1\n",
    "                    wrong_questions[idx] = wrong_questions.get(idx, 0) + 1\n",
    "        lst_of_scores.append(score)\n",
    "\n",
    "    return lst_of_scores, skip_questions, wrong_questions\n",
    "lst_of_scores, skip_questions, wrong_questions = calculate_scores(correct_exams, answer_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistic_scores(lst_of_scores, skip_questions, wrong_questions):\n",
    "    print(\"Total students with high scores:\", sum(score > 80 for score in lst_of_scores))\n",
    "    print(\"Mean (average) score:\", np.mean(lst_of_scores))\n",
    "    print(\"Highest score:\", max(lst_of_scores))\n",
    "    print(\"Lowest score:\", min(lst_of_scores))\n",
    "    print(\"Range of scores:\", max(lst_of_scores) - min(lst_of_scores))\n",
    "    print(\"Median score:\", np.median(lst_of_scores))\n",
    "\n",
    "    most_skip_values = max(skip_questions.values())\n",
    "    most_wrong_values = max(wrong_questions.values())\n",
    "\n",
    "    most_skip_keys = [key for key, value in skip_questions.items() if value == most_skip_values]\n",
    "    print(\"Question that most people skip:\")\n",
    "    for question in sorted(most_skip_keys):\n",
    "        print(f\"{question} - {most_skip_values} - {most_skip_values / 25}\")\n",
    "\n",
    "    most_wrong_keys = [key for key, value in wrong_questions.items() if value == most_wrong_values]\n",
    "    print(\"Question that most people answer incorrectly:\")\n",
    "    for question in sorted(most_wrong_keys):\n",
    "        print(f\"{question} - {most_wrong_values} - {most_wrong_values / 25}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total students with high scores: 17\n",
      "Mean (average) score: 76.6734693877551\n",
      "Highest score: 92\n",
      "Lowest score: 59\n",
      "Range of scores: 33\n",
      "Median score: 77.0\n",
      "Question that most people skip:\n",
      "4 - 9 - 0.36\n",
      "Question that most people answer incorrectly:\n",
      "4 - 9 - 0.36\n",
      "15 - 9 - 0.36\n"
     ]
    }
   ],
   "source": [
    "statistic_scores(lst_of_scores, skip_questions, wrong_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_scores(correct_exams, lst_of_scores, name_file):\n",
    "    res = []\n",
    "    for exam, score in zip(correct_exams, lst_of_scores):\n",
    "        res.append([exam.split(\",\")[0], score])\n",
    "\n",
    "    with open(f\"Data_Files/output/{name_file}_grades.txt\", 'a') as f:\n",
    "        for element in res:\n",
    "            f.write(\",\".join(map(str, element)) + \"\\n\")\n",
    "\n",
    "update_scores(correct_exams, lst_of_scores, name_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Nam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
